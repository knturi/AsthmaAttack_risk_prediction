{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import plotnine\n",
    "from plotnine import *  # Provides a ggplot-like interface to matplotlib.\n",
    "from IPython.display import display\n",
    "\n",
    "## Plot setup.\n",
    "theme_set(theme_bw(base_size = 11)) # Default theme for plots.\n",
    "\n",
    "def get_boxplot_fun_data(df):\n",
    "  \"\"\"Returns a data frame with a y position and a label, for use annotating ggplot boxplots.\n",
    "\n",
    "  Args:\n",
    "    d: A data frame.\n",
    "  Returns:\n",
    "    A data frame with column y as max and column label as length.\n",
    "  \"\"\"\n",
    "  d = {'y': max(df), 'label': f'N = {len(df)}'}\n",
    "  return(pd.DataFrame(data=d, index=[0]))\n",
    "\n",
    "# NOTE: if you get any errors from this cell, restart your kernel and run it again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving each table as data frames to workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This code copies file in your Google Bucket and loads it into a dataframe\n",
    "\n",
    "name_of_file_in_bucket = 'person_df.csv'\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file from the bucket to the current working space\n",
    "os.system(f\"gsutil cp '{my_bucket}/data/{name_of_file_in_bucket}' .\")\n",
    "\n",
    "print(f'[INFO] {name_of_file_in_bucket} is successfully downloaded into your working space')\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe = pd.read_csv(name_of_file_in_bucket)\n",
    "my_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code copies file in your Google Bucket and loads it into a dataframe\n",
    "\n",
    "name_of_file_in_bucket = 'condition_df.csv'\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file from the bucket to the current working space\n",
    "os.system(f\"gsutil cp '{my_bucket}/data/{name_of_file_in_bucket}' .\")\n",
    "\n",
    "print(f'[INFO] {name_of_file_in_bucket} is successfully downloaded into your working space')\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe = pd.read_csv(name_of_file_in_bucket)\n",
    "my_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code copies file in your Google Bucket and loads it into a dataframe\n",
    "\n",
    "name_of_file_in_bucket = 'measurement_df.csv'\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file from the bucket to the current working space\n",
    "os.system(f\"gsutil cp '{my_bucket}/data/{name_of_file_in_bucket}' .\")\n",
    "\n",
    "print(f'[INFO] {name_of_file_in_bucket} is successfully downloaded into your working space')\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe = pd.read_csv(name_of_file_in_bucket)\n",
    "my_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code copies file in your Google Bucket and loads it into a dataframe\n",
    "\n",
    "name_of_file_in_bucket = 'drug_df.csv'\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file from the bucket to the current working space\n",
    "os.system(f\"gsutil cp '{my_bucket}/data/{name_of_file_in_bucket}' .\")\n",
    "\n",
    "print(f'[INFO] {name_of_file_in_bucket} is successfully downloaded into your working space')\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe = pd.read_csv(name_of_file_in_bucket)\n",
    "my_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code copies file in your Google Bucket and loads it into a dataframe\n",
    "\n",
    "name_of_file_in_bucket = 'survey_df.csv'\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file from the bucket to the current working space\n",
    "os.system(f\"gsutil cp '{my_bucket}/data/{name_of_file_in_bucket}' .\")\n",
    "\n",
    "print(f'[INFO] {name_of_file_in_bucket} is successfully downloaded into your working space')\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe = pd.read_csv(name_of_file_in_bucket)\n",
    "my_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code copies file in your Google Bucket and loads it into a dataframe\n",
    "\n",
    "name_of_file_in_bucket = 'observation_df.csv'\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file from the bucket to the current working space\n",
    "os.system(f\"gsutil cp '{my_bucket}/data/{name_of_file_in_bucket}' .\")\n",
    "\n",
    "print(f'[INFO] {name_of_file_in_bucket} is successfully downloaded into your working space')\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe = pd.read_csv(name_of_file_in_bucket)\n",
    "my_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data each separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data frames from google bucket to workspace \n",
    "import pandas as pd\n",
    "person_df=pd.read_csv('person_df.csv')\n",
    "condition_df=pd.read_csv('condition_df.csv')\n",
    "measurement_df=pd.read_csv('measurement_df.csv')\n",
    "drug_df=pd.read_csv('drug_df.csv')\n",
    "survey_df=pd.read_csv('survey_df.csv')\n",
    "observation_df=pd.read_csv('observation_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleaning person data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "person_df=pd.read_csv('person_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleaning and reshaping observation dataÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_df=pd.read_csv('observation_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_df.person_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_df=observation_df.drop(observation_df[observation_df['value_as_concept_name'] == 'PMI: Skip'].index)\n",
    "#observation_df.sort_values(by=['person_id','observation_datetime']).head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_df=observation_df.pivot_table(index=['observation_datetime','person_id'],\n",
    "                                              columns='standard_concept_name', values='value_as_concept_name', aggfunc='first').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_df=observation_df.rename(\n",
    "    columns={\n",
    "        'Alcohol: 6 or More Drinks Occurrence':'alcohol6or_more',\n",
    "        'Are you covered by health insurance or some other kind of health care plan [PhenX]':'Health_insurance_cov',\n",
    "        'Cigar Smoking: Cigar Smoke Participant':'cigar_smoke',\n",
    "        'Current occupational status [SAMHSA]':'Current_occupation_status',\n",
    "        'Electronic Smoking: Electric Smoke Participant':'electronic_cigarate_smoke',\n",
    "        'Health Insurance: Health Insurance Type':'Health_insurance_type',\n",
    "        'Home Own: Current Home Own':'current_home_own_rent',\n",
    "        'Hookah Smoking: Hookah Smoke Participant':'hookah_smoke',\n",
    "        'How often have you been bothered by emotional problems such as feeling anxious, depressed or irritable in past 7 days [PROMIS]':'howmuch_emotional_problem_7yrs',\n",
    "        'Insurance: Healthcare Coverage':'insurance_healthcare_coverage',\n",
    "        'Living Situation: Stable House Concern':'stable_house_concern',\n",
    "        'Marital status':'marital_status',\n",
    "        'Race':'race',\n",
    "        'Race: What Race Ethnicity':'race_ethnicity',\n",
    "        'Recreational Drug Use: Which Drugs Used':'resreational_drug',\n",
    "        'Sex':'sex',\n",
    "        'Smoked at least 100 cigarettes in entire life':'smoked100cigarettes',\n",
    "        'Total combined household income range in last year':'hh_income_last_yr',\n",
    "        'What is the highest grade or level of schooling you completed [SAMHSA]':'highest_grade_edu'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "observation_df.sort_values(by=['person_id','observation_datetime']).head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_df=observation_df.drop(columns=['sex','race','race', 'Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_df_w=observation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet assumes you run setup first\n",
    "\n",
    "# This code saves your dataframe into a csv file in a \"data\" folder in Google Bucket\n",
    "\n",
    "# Replace df with THE NAME OF YOUR DATAFRAME\n",
    "my_dataframe = observation_df_w   \n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename = 'observation_df_wide.csv'\n",
    "\n",
    "########################################################################\n",
    "##\n",
    "################# DON'T CHANGE FROM HERE ###############################\n",
    "##\n",
    "########################################################################\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "os.system(f\"gsutil cp './{destination_filename}' '{my_bucket}/data/'\")\n",
    "print(f'[INFO] {destination_filename} is successfully uploaded in your bucket.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and reshaping survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df=pd.read_csv('survey_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df=survey_df.drop(survey_df[survey_df['answer'] == 'PMI: Skip'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df_w=survey_df.pivot_table(index=['survey_datetime','person_id'],\n",
    "                                              columns='question', values='answer', aggfunc='first').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code saves your dataframe into a csv file in a \"data\" folder in Google Bucket\n",
    "\n",
    "# Replace df with THE NAME OF YOUR DATAFRAME\n",
    "my_dataframe = survey_df_w   \n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename = 'survey_df_wide.csv'\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "os.system(f\"gsutil cp './{destination_filename}' '{my_bucket}/data/'\")\n",
    "print(f'[INFO] {destination_filename} is successfully uploaded in your bucket.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleaning condition data and creating exacebration variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_df=pd.read_csv('condition_df.csv')\n",
    "condition_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "condition_df['exacerbation']=np.where(condition_df['standard_concept_name'].str.contains('exacerbation'), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_df.sort_values(by=['person_id','condition_start_datetime']).head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_df['exacerbation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_df['condition_start_datetime']=pd.to_datetime(condition_df['condition_start_datetime'])\n",
    "condition_df['condition_end_datetime']=pd.to_datetime(condition_df['condition_end_datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subseting  and cleaning, and pivoting (wide) measurement data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "measurement_df=pd.read_csv('measurement_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_df=measurement_df.drop(columns=['range_high','range_low','value_as_concept_name',\n",
    "                             'measurement_type_concept_name', 'standard_vocabulary',\n",
    "                             'visit_occurrence_concept_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_df=measurement_df.dropna(subset=['value_as_number'])\n",
    "measurement_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_df=measurement_df[measurement_df['standard_concept_name'].str.contains('Monocytes', case=True, regex=True)|\n",
    "                              measurement_df['standard_concept_name'].str.contains('Leukocytes', case=True, regex=True)|\n",
    "                              measurement_df['standard_concept_name'].str.contains('Neutrophils', case=True, regex=True)|\n",
    "                              measurement_df['standard_concept_name'].str.contains('Eosinophils', case=True, regex=True)|\n",
    "                              measurement_df['standard_concept_name'].str.contains('Lymphocytes', case=True, regex=True)|\n",
    "                              measurement_df['standard_concept_name'].str.contains('Basophills', case=True, regex=True)|\n",
    "                              measurement_df['standard_concept_name'].str.contains('BMI', case=True, regex=True)|\n",
    "                              measurement_df['standard_concept_name'].str.contains('Albumin [Mass/volume] in Serum or Plasma', case=True, regex=True)|\n",
    "                              measurement_df['standard_concept_name'].str.contains('Bilirubin.total [Mass/volume] in Serum or Plasma', case=True, regex=True)|\n",
    "                              measurement_df['standard_concept_name'].str.contains('Bilirubin.total [Mass/volume] in Blood', case=True, regex=True)|\n",
    "                              measurement_df['standard_concept_name'].str.contains('IgE', case=False, regex=True)|\n",
    "                              measurement_df['standard_concept_name'].str.contains('Hemoglobin [Mass/volume] in Blood', case=True, regex=True)|\n",
    "                              measurement_df['standard_concept_name'].str.contains('Nitrite', case=False, regex=True)|\n",
    "                              measurement_df['standard_concept_name'].str.contains('Protein', case=False, regex=True)|\n",
    "                              measurement_df['standard_concept_name'].str.contains('Urobilinogen', case=False, regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "conditions=[(measurement_df['standard_concept_name'].str.contains('Monocytes', case=True, regex=True)),\n",
    "           (measurement_df['standard_concept_name'].str.contains('Leukocytes', case=True, regex=True)),\n",
    "           (measurement_df['standard_concept_name'].str.contains('Neutrophils', case=True, regex=True)),\n",
    "           (measurement_df['standard_concept_name'].str.contains('Eosinophils', case=True, regex=True)),\n",
    "           (measurement_df['standard_concept_name'].str.contains('Lymphocytes', case=True, regex=True)),\n",
    "           (measurement_df['standard_concept_name'].str.contains('Basophills', case=True, regex=True)),\n",
    "           (measurement_df['standard_concept_name'].str.contains('BMI', case=True, regex=True)),\n",
    "           (measurement_df['standard_concept_name'].str.contains('Albumin', case=True, regex=True)),\n",
    "           (measurement_df['standard_concept_name'].str.contains('Bilirubin', case=True, regex=True)),\n",
    "           (measurement_df['standard_concept_name'].str.contains('IgE', case=False, regex=True)),\n",
    "           (measurement_df['standard_concept_name'].str.contains('Hemoglobin', case=True, regex=True)),\n",
    "           (measurement_df['standard_concept_name'].str.contains('Nitrite', case=False, regex=True)),\n",
    "           (measurement_df['standard_concept_name'].str.contains('Protein', case=False, regex=True)),\n",
    "           (measurement_df['standard_concept_name'].str.contains('Urobilinogen', case=False, regex=True))]\n",
    "\n",
    "values=['Monocytes','Leukocytes','Neutrophils','Eosinophils',\n",
    "        'Lymphocytes','Basophills','BMI','Albumin','Bilirubin',\n",
    "        'IgE','Hemoglobin','Nitrite', 'Protein','Urobilinogen']\n",
    "\n",
    "measurement_df['variable'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_df=measurement_df.pivot_table(index=['measurement_datetime','person_id'],columns='variable', values='value_as_number').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code saves your dataframe into a csv file in a \"data\" folder in Google Bucket\n",
    "\n",
    "my_dataframe = measurement_df_w   \n",
    "\n",
    "\n",
    "destination_filename = 'measurement_df_wide.csv'\n",
    "\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "os.system(f\"gsutil cp './{destination_filename}' '{my_bucket}/data/'\")\n",
    "print(f'[INFO] {destination_filename} is successfully uploaded in your bucket.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleaning drug data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "drug_df=pd.read_csv('drug_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_df.sort_values(by=['person_id','drug_exposure_start_datetime']).head(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in drug_df['standard_concept_name'].unique():\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_df=drug_df.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "drug_df=drug_df.dropna(subset=['standard_concept_name'])\n",
    "drug_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "SABA=['albuterol','ipratropium','Levalbuterol', 'Terbutaline','Pirbuterol','Salbutamol']\n",
    "Inhaled_corticosteroids=['budesonide','Beclomethasone','Pulmicort','Ciclesonide','Flunisolide',\n",
    "                         'Fluticasone','Mometasone'] \n",
    "LABA=['formoterol','Fluticasone','salmeterol','vilantero','Indacaterol','Olodaerol'] \n",
    "Leukotriene_modifiers=['Montelukast','Zafirlukast','Zileuton','Arformoterol','Carmoterol']  \n",
    "Methylxanthines_and_Monoclonals=['Theophylline','Omalizumab','Aminophylline'] \n",
    "Anti_histamines=['Azelastine','methylprednisolone','Phenylephrine','diphenhydramine',\n",
    "                 'Chlorpheniramine', 'Desloratadine', 'Fexofenadine','Levocetirizine',\n",
    "                 'Loratadine','Cetirizine','pseudoephedrine','Oxymetazoline','Levocetirizine',\n",
    "                 'Tetrahydrozoline', 'Olopatadine','Ketotifen','Triprolidine','Cromoglicic',\n",
    "                 'Levocetirizine', 'Xylometazoline','Antazoline']\n",
    "Syst_corticosteroids=['cortisone','prednisone','prednisolone','methylprednisolone',\n",
    "                      'dexamethasone','betamethasone','hydrocortisone','Triamcinolone']\n",
    "Sympathomimetics=['Phenylpropanolamine','Amphetamine','Methoxamine','Epinephrine','Metaraminol',\n",
    "                  'Labetalol','Phenylephrine','Norepinephrine','Midodrine','Phentermine']\n",
    "\n",
    "\n",
    "conditions=[\n",
    "    drug_df['standard_concept_name'].astype(str).str.contains('|'.join(SABA),case=False, na=False),\n",
    "    drug_df['standard_concept_name'].astype(str).str.contains('|'.join(Inhaled_corticosteroids),case=False,na=False),\n",
    "    drug_df['standard_concept_name'].astype(str).str.contains('|'.join(LABA),case=False, na=False),\n",
    "    drug_df['standard_concept_name'].astype(str).str.contains('|'.join(Leukotriene_modifiers),case=False,na=False),\n",
    "    drug_df['standard_concept_name'].astype(str).str.contains('|'.join(Methylxanthines_and_Monoclonals),case=False,na=False),\n",
    "    drug_df['standard_concept_name'].astype(str).str.contains('|'.join(Anti_histamines),case=False,na=False),\n",
    "    drug_df['standard_concept_name'].astype(str).str.contains('|'.join(Syst_corticosteroids),case=False,na=False),\n",
    "    drug_df['standard_concept_name'].astype(str).str.contains('|'.join(Sympathomimetics),case=False,na=False)\n",
    "]\n",
    "\n",
    "\n",
    "choices=[\n",
    "    'SABA',\n",
    "    'Inhaled corticosteroids', 'LABA', 'Leukotriene modifiers',\n",
    "    'Methylxanthines and Monoclonals', 'Anti-histamines', 'Syst_corticosteroids','Sympathomimetics'\n",
    "]\n",
    "\n",
    "\n",
    "    \n",
    "drug_df['drug_class'] =np.select(conditions, choices, 'other')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#drug_df[drug_df['drug_class']=='other'].head(60)\n",
    "drug_df['drug_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_df_w=drug_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code saves your dataframe into a csv file in a \"data\" folder in Google Bucket\n",
    "\n",
    "# Replace df with THE NAME OF YOUR DATAFRAME\n",
    "my_dataframe = drug_df_w   \n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename = 'drug_df_wide.csv'\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "os.system(f\"gsutil cp './{destination_filename}' '{my_bucket}/data/'\")\n",
    "print(f'[INFO] {destination_filename} is successfully uploaded in your bucket.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip\n",
    "#!pip install MedCodes\n",
    "from medcodes.drugs.standardization import Drug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging the cleaned data frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge person data to condition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "person_df=pd.read_csv('person_df.csv')\n",
    "condition_df=pd.read_csv('condition_df.csv')\n",
    "person_cond=pd.merge(person_df,\n",
    "                   condition_df,\n",
    "                   on='person_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_cond.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge person_condition data to observation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_df_wide=pd.read_csv('observation_df_wide.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "person_cond['condition_start_datetime']=pd.to_datetime(person_cond['condition_start_datetime'])\n",
    "observation_df_wide['observation_datetime']=pd.to_datetime(observation_df_wide['observation_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_cond=person_cond.sort_values(by=['condition_start_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "person_cond_obsv=pd.merge(person_cond,\n",
    "                   observation_df_wide,\n",
    "                   on='person_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_cond_obsv[['person_id','condition_start_datetime',\n",
    "                  'observation_datetime']].sort_values(by=['person_id',\n",
    "                                                           'condition_start_datetime',\n",
    "                                                           'observation_datetime']).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_cond_obsv.sort_values(by=['person_id','condition_start_datetime','observation_datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge person_condition_observ data to measurement data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_cond_obsv=person_cond_obsv.sort_values(by=['condition_start_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "person_cond_obsv['condition_start_datetime']=pd.to_datetime(person_cond_obsv['condition_start_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_cond_obsv=person_cond_obsv.drop(columns='stop_reason')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "person_cond_obsv['exacerbation']=np.where(person_cond_obsv['standard_concept_name'].str.contains('exacerbation'), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_df_wide=pd.read_csv('measurement_df_wide.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurement_df_wide['measurement_datetime']=pd.to_datetime(measurement_df_wide['measurement_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_cond_obsv_measu=pd.merge_asof(measurement_df_wide, person_cond_obsv, \n",
    "                   left_on='measurement_datetime', \n",
    "                   right_on='condition_start_datetime',\n",
    "                   left_by=['person_id'],\n",
    "                   right_by=['person_id'],allow_exact_matches=True,\n",
    "                   direction='forward',tolerance=pd.Timedelta(\"5y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_cond_obsv_measu.sort_values(by=['person_id','measurement_datetime',\n",
    "                     'condition_start_datetime']).head(500)[['person_id','measurement_datetime','observation_datetime',\n",
    "                                                             'condition_start_datetime','standard_concept_name']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "person_cond_obsv_measu[person_cond_obsv_measu['person_id']==1000109][['person_id','measurement_datetime','observation_datetime',\n",
    "                                  'condition_start_datetime','standard_concept_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "person_cond_obsv_measu.dropna(subset=['condition_start_datetime']).sort_values(by=['person_id',\n",
    "                                                                 'condition_start_datetime']) [['person_id',\n",
    "                                                                                                'measurement_datetime','observation_datetime',\n",
    "                                                                                                'condition_start_datetime','standard_concept_name']].head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_cond_obsv_measu=person_cond_obsv_measu.dropna(subset=['condition_start_datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge person_condition_observation_measurement data to drug data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_df_wide=pd.read_csv('drug_df_wide.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_df_wide['drug_exposure_start_datetime']=pd.to_datetime(drug_df_wide['drug_exposure_start_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_df_wide=drug_df_wide.sort_values('drug_exposure_start_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_cond_obsv_measu=person_cond_obsv_measu.sort_values(by=['condition_start_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_cond_obsv_measu_drug=pd.merge_asof(person_cond_obsv_measu, drug_df_wide, \n",
    "                   left_on='condition_start_datetime', \n",
    "                   right_on='drug_exposure_start_datetime',\n",
    "                   left_by=['person_id'],\n",
    "                   right_by=['person_id'],allow_exact_matches=True,\n",
    "                   direction='backward',tolerance=pd.Timedelta(\"10y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_cond_obsv_measu_drug.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_cond_obsv_measu_drug.sort_values(by=['person_id', 'drug_exposure_start_datetime',\n",
    "                          'condition_start_datetime']) [['person_id',\n",
    "                                                         'measurement_datetime','observation_datetime','drug_class',\n",
    "                                                         'condition_start_datetime','standard_concept_name_x',\n",
    "                                                         'standard_concept_name_y','drug_exposure_start_datetime']].head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_cond_obsv_measu_drug[person_cond_obsv_measu_drug['person_id']==1000151][['person_id','measurement_datetime',\n",
    "                                            'observation_datetime','drug_class',\n",
    "                                            'condition_start_datetime','standard_concept_name_x',\n",
    "                                            'standard_concept_name_y','drug_exposure_start_datetime']].head(200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code saves your dataframe into a csv file in a \"data\" folder in Google Bucket\n",
    "\n",
    "# Replace df with THE NAME OF YOUR DATAFRAME\n",
    "my_dataframe = person_cond_obsv_measu_drug   \n",
    "\n",
    "destination_filename = 'asthma_exaceb_df.csv'\n",
    "\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "os.system(f\"gsutil cp './{destination_filename}' '{my_bucket}/data/'\")\n",
    "print(f'[INFO] {destination_filename} is successfully uploaded in your bucket.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge person_condition_observation_measurement_drug data to survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df_wide=pd.read_csv('survey_df_wide.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "person_co_dr_mr_svy[person_co_dr_mr_svy['person_id']==1000109][['person_id','measurement_datetime',\n",
    "                                            'observation_datetime','survey_datetime',\n",
    "                                            'condition_start_datetime','standard_concept_name_x','drug_class',\n",
    "                                            'standard_concept_name_y','drug_exposure_start_datetime',\n",
    "                                                                'Respiratory: Asthma Currently',\n",
    "                                                               'Respiratory: How Old Were You Asthma',\n",
    "                                                               'Respiratory: Rx Meds for Asthma']].head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving combined ands cleaned data to workspace in google bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code saves your dataframe into a csv file in a \"data\" folder in Google Bucket\n",
    "\n",
    "# Replace df with THE NAME OF YOUR DATAFRAME\n",
    "my_dataframe = person_co_dr_mr_svy_obs   \n",
    "\n",
    "destination_filename = 'person_cond_drug_mearsu_svy_obs.csv'\n",
    "\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "os.system(f\"gsutil cp './{destination_filename}' '{my_bucket}/data/'\")\n",
    "print(f'[INFO] {destination_filename} is successfully uploaded in your bucket.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
